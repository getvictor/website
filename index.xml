<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Victor on Software</title><link>https://victoronsoftware.com/</link><description>Recent content on Victor on Software</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 04 Jan 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://victoronsoftware.com/index.xml" rel="self" type="application/rss+xml"/><item><title>Fuzz testing in Go</title><link>https://victoronsoftware.com/posts/fuzz-testing-with-go/</link><pubDate>Thu, 04 Jan 2024 00:00:00 +0000</pubDate><guid>https://victoronsoftware.com/posts/fuzz-testing-with-go/</guid><description>&lt;img src="https://victoronsoftware.com/posts/fuzz-testing-with-go/fuzz.png" alt="Featured image of post Fuzz testing in Go" />&lt;div class="video-wrapper">
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/4emTXow54F4"
allowfullscreen
title="YouTube Video"
>
&lt;/iframe>
&lt;/div>
&lt;p>Fuzz testing is a software automated testing technique where random inputs are provided to the software under test. My background is in
hardware verification, which uses sophisticated methodologies for pseudorandom testing, so I wanted to see what the Go library had to offer
out of the box.&lt;/p>
&lt;p>A &lt;a class="link" href="https://go.dev/doc/security/fuzz" target="_blank" rel="noopener"
>Go fuzz test&lt;/a> can run as:&lt;/p>
&lt;ul>
&lt;li>a normal unit test&lt;/li>
&lt;li>a test with fuzzing&lt;/li>
&lt;/ul>
&lt;p>A fuzz test is written similarly to a normal unit test in a *&lt;strong>_test.go&lt;/strong> file, with the following changes. It must have a &lt;strong>Fuzz&lt;/strong> prefix
and use the &lt;strong>testing.F&lt;/strong> struct instead of the usual &lt;strong>testing.T&lt;/strong> struct.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-go" data-lang="go">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">func&lt;/span> &lt;span style="color:#a6e22e">FuzzSample&lt;/span>(&lt;span style="color:#a6e22e">f&lt;/span> &lt;span style="color:#f92672">*&lt;/span>&lt;span style="color:#a6e22e">testing&lt;/span>.&lt;span style="color:#a6e22e">F&lt;/span>) {
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Here is a workflow for using fuzz testing. First, you create a fuzz test. Then, you run it with fuzzing to automatically find failing corner
cases and make any fixes. Thirdly, you include the test and the corner cases in your continuous integration testing suite.&lt;/p>
&lt;h2 id="create-a-fuzz-test">Create a fuzz test&lt;/h2>
&lt;p>When creating a fuzz test, you should provide a corpus of initial seed inputs. These are the inputs the test will use before applying
randomization. Add the seed corpus with the &lt;strong>Add&lt;/strong> method. For example:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-go" data-lang="go">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">f&lt;/span>.&lt;span style="color:#a6e22e">Add&lt;/span>(&lt;span style="color:#a6e22e">tc&lt;/span>.&lt;span style="color:#a6e22e">Num&lt;/span>, &lt;span style="color:#a6e22e">tc&lt;/span>.&lt;span style="color:#a6e22e">Name&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">f&lt;/span>.&lt;span style="color:#a6e22e">Add&lt;/span>(uint8(&lt;span style="color:#ae81ff">0&lt;/span>), &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The inputs to the &lt;strong>Add&lt;/strong> method indicate which types will be fuzzed, and these types must match the subsequent call to the &lt;strong>Fuzz&lt;/strong> method:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-go" data-lang="go">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">f&lt;/span>.&lt;span style="color:#a6e22e">Fuzz&lt;/span>(&lt;span style="color:#66d9ef">func&lt;/span>(&lt;span style="color:#a6e22e">t&lt;/span> &lt;span style="color:#f92672">*&lt;/span>&lt;span style="color:#a6e22e">testing&lt;/span>.&lt;span style="color:#a6e22e">T&lt;/span>, &lt;span style="color:#a6e22e">num&lt;/span> &lt;span style="color:#66d9ef">uint8&lt;/span>, &lt;span style="color:#a6e22e">name&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span>) {
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The fuzz test can randomize any number of inputs, as long as they are one of the supported types.&lt;/p>
&lt;h2 id="run-the-test-with-fuzzing">Run the test with fuzzing&lt;/h2>
&lt;p>To run the test with fuzzing, use the &lt;strong>-fuzz&lt;/strong> switch, like:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>go test -fuzz FuzzSample
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The test will continuously run on all your CPUs until it fails, or you kill it:&lt;/p>
&lt;pre tabindex="0">&lt;code>=== RUN FuzzSample
fuzz: elapsed: 0s, gathering baseline coverage: 0/11 completed
fuzz: elapsed: 0s, gathering baseline coverage: 11/11 completed, now fuzzing with 12 workers
fuzz: elapsed: 3s, execs: 432199 (144036/sec), new interesting: 0 (total: 11)
fuzz: elapsed: 6s, execs: 871147 (146328/sec), new interesting: 0 (total: 11)
&lt;/code>&lt;/pre>&lt;p>A sample failure:&lt;/p>
&lt;pre tabindex="0">&lt;code>failure while testing seed corpus entry: FuzzSample/49232526a5eabbdc
fuzz: elapsed: 1s, gathering baseline coverage: 10/11 completed
--- FAIL: FuzzSample (1.03s)
--- FAIL: FuzzSample (0.00s)
fuzz_test.go:21: Found 0
&lt;/code>&lt;/pre>&lt;p>The failures are automatically added to the seed corpus. The seed corpus includes the initial inputs that were added with the &lt;strong>Add&lt;/strong> method as
well as any new fails. These new seed corpus files are automatically created in the &lt;strong>testdata/fuzz/Fuzz&lt;/strong>* directory. Sample contents of one
such file:&lt;/p>
&lt;pre tabindex="0">&lt;code>go test fuzz v1
byte(&amp;#39;\x01&amp;#39;)
string(&amp;#34;0a0000&amp;#34;)
&lt;/code>&lt;/pre>&lt;p>Adding the failure to the seed corpus means that the failing case will always run when this test is run again as a unit test or with
fuzzing.&lt;/p>
&lt;p>Now, you must fix the failing test and continue the loop of fuzzing and fixing.&lt;/p>
&lt;h2 id="include-the-test-in-continuous-integration">Include the test in continuous integration&lt;/h2>
&lt;p>When checking in the test to your repository, you must either include the &lt;strong>testdata/fuzz/Fuzz&lt;/strong>* files or convert those files into individual
&lt;strong>Add&lt;/strong> method calls in your test. Once the test is checked in, all the inputs in the seed corpus will run as part of the standard Go unit test
flow.&lt;/p>
&lt;h2 id="initial-impressions">Initial impressions&lt;/h2>
&lt;p>Fuzz testing appears to be a good approach to help the development of small functions with limited scope. The library documentation mentions
the following about the function under test:&lt;/p>
&lt;blockquote>
&lt;p>This function should be fast and deterministic, and its behavior should not depend on shared state.&lt;/p>
&lt;/blockquote>
&lt;p>I plan to give fuzzing a try the next time I develop such a function. I will share the results on this blog.&lt;/p>
&lt;h2 id="concerns-and-issues">Concerns and Issues&lt;/h2>
&lt;p>Native fuzzing support was added to Go in 1.18 and seems like a good initial approach. However, it feels limited in features and usability.
The types of functions, fast and deterministic, that fuzzing is intended for are generally not very interesting when testing real
applications. They are good examples for students learning how to code. However, more interesting testing scenarios include:&lt;/p>
&lt;ul>
&lt;li>Functions accessing remote resources in parallel, such as APIs or databases&lt;/li>
&lt;li>Functions with asynchronous code&lt;/li>
&lt;/ul>
&lt;p>Secondly, the fuzzing library does not provide a good way to guide the randomization of inputs and does not give feedback about the input
state space already covered. It does provide line coverage information, but that doesn&amp;rsquo;t help for unknown corner cases.&lt;/p>
&lt;p>If one of my inputs is intended to be a percentage, then I want most of the fuzzing to concentrate on the legal range of 0-100, as opposed
to all numbers. This lack of constraints becomes a problem when adding additional inputs to the fuzzing function, as the available state
space of inputs expands exponentially. If the state space of inputs is huge, there is no guarantee that fuzzing accomplished its goal of
finding all corner cases, leaving the developer with a false sense of confidence in their code.&lt;/p>
&lt;p>Lastly, the fuzz test is hard to maintain. The seed corpus is stored in files without any context regarding what corner case each seed is
hitting. Software engineers unfamiliar with fuzz testing will find this extremely confusing. If the fuzz test needs to be extended in the
future with additional inputs or different types, the old seed corpus will become useless. It will be worse than useless &amp;ndash; the test will
not run, and the developer unfamiliar with fuzz testing will not have a clear idea why.&lt;/p>
&lt;pre>&lt;code>fuzz_test.go:16: wrong number of values in corpus entry: 2, want 3
&lt;/code>&lt;/pre>
&lt;p>That said, understanding the fuzz testing limitation, I’m willing to try fuzz testing for more interesting test cases, such as database
accesses. I will report my findings in a future post.&lt;/p>
&lt;p>GitHub gist:
&lt;script src="https://gist.github.com/getvictor/24baadcc9cf08e7d7a6028ad54ff2aba.js">&lt;/script>
&lt;/p></description></item><item><title>Understanding the intricacies of Fleet policies</title><link>https://victoronsoftware.com/posts/understanding-the-intricacies-of-fleet-policies/</link><pubDate>Sat, 30 Dec 2023 00:00:00 +0000</pubDate><guid>https://victoronsoftware.com/posts/understanding-the-intricacies-of-fleet-policies/</guid><description>&lt;img src="https://victoronsoftware.com/posts/understanding-the-intricacies-of-fleet-policies/understanding-the-intricacies-of-fleet-policies-main-policies-page-1999x978@2x.png" alt="Featured image of post Understanding the intricacies of Fleet policies" />&lt;div class="video-wrapper">
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/A-Qapp7vYJk"
allowfullscreen
title="YouTube Video"
>
&lt;/iframe>
&lt;/div>
&lt;p>In the ever-evolving landscape of device management and cybersecurity, understanding the mechanics behind tools like Fleet is not just about technical curiosity; it&amp;rsquo;s about empowering IT professionals to safeguard digital assets more effectively. &lt;a class="link" href="https://fleetdm.com" target="_blank" rel="noopener"
>Fleet&lt;/a> gathers telemetry from various devices, from laptops to virtual machines, using &lt;a class="link" href="https://www.osquery.io/" target="_blank" rel="noopener"
>osquery&lt;/a>. At the heart of this system lies a crucial feature: &lt;a class="link" href="https://fleetdm.com/securing/what-are-fleet-policies" target="_blank" rel="noopener"
>Fleet policies&lt;/a>.&lt;/p>
&lt;p>Policies in Fleet are more than just rules; they are the gatekeepers of your device&amp;rsquo;s security, ensuring stringent adherence to security standards. By dissecting how Fleet policies operate &amp;ldquo;under the hood,&amp;rdquo; IT administrators and security professionals can gain invaluable insights. These insights allow for setting up efficient security protocols and rapid response to potential vulnerabilities, a necessity in a landscape where cyber threats are constantly evolving. This article delves into the inner workings of Fleet policies, providing you with the knowledge to better configure, manage, and leverage these policies for optimal device security and efficiency.&lt;/p>
&lt;h2 id="policy-creation">Policy creation&lt;/h2>
&lt;p>Policies can be created from the web UI, the command-line interface called &lt;code>fleetctl&lt;/code> with config files, or the REST API. The user creates a policy and selects which devices need to be checked using that policy. Policies can be global or team-specific.&lt;/p>
&lt;p>When a policy is created, a record for it is stored in the &lt;strong>policies&lt;/strong> table of the MySQL database. A Fleet deployment consists of several servers behind a load balancer, so storing the record in the DB makes all servers aware of the new policy.&lt;/p>
&lt;figure>&lt;img src="understanding-the-intricacies-of-fleet-policies-policy-creation-1280x720@2x.png"/>
&lt;/figure>
&lt;h2 id="policy-execution">Policy execution&lt;/h2>
&lt;p>Policies are executed on the devices, which are called &lt;strong>hosts&lt;/strong> in Fleet, according to the &lt;a class="link" href="https://fleetdm.com/docs/configuration/fleet-server-configuration#osquery-policy-update-interval" target="_blank" rel="noopener"
>FLEET_OSQUERY_POLICY_UPDATE_INTERVAL&lt;/a>, which is set to 1 hour by default. This interval can be adjusted with the environment variable or set from the server’s command line.&lt;/p>
&lt;p>Policies are simply SQL queries that return a true or false result, so the flow they use on the hosts is the same as other queries. Hosts check in with Fleet servers every 10 seconds (the default) and access the &lt;code>/api/v1/osquery/distributed/read&lt;/code> API endpoint. The server checks when the policy was last executed to determine whether it should be executed again. If so, the server adds the policy to its response. For example, this policy in the server response checks if the macOS firewall is enabled:&lt;/p>
&lt;pre tabindex="0">&lt;code>{
&amp;#34;queries&amp;#34;: {
&amp;#34;fleet_policy_query_9&amp;#34;: &amp;#34;SELECT 1 FROM alf WHERE global_state &amp;gt;= 1;&amp;#34;
},
&amp;#34;discovery&amp;#34;: {
&amp;#34;fleet_policy_query_9&amp;#34;: &amp;#34;SELECT 1&amp;#34;
}
}
&lt;/code>&lt;/pre>&lt;p>Once the host has executed the policy, it writes the result to the server. The server updates the result in the &lt;strong>policy_membership&lt;/strong> table of the MySQL database. At this point, the Host Details page on the web UI is updated with the policy result.&lt;/p>
&lt;figure>&lt;img src="understanding-the-intricacies-of-fleet-policies-host-policy-view-1818x1999@2x.png"/>
&lt;/figure>
&lt;h2 id="force-policy-execution-on-a-device">Force policy execution on a device&lt;/h2>
&lt;p>The user can force the host to execute all of its policies by clicking the &lt;strong>Refetch&lt;/strong> link:&lt;/p>
&lt;figure>&lt;img src="understanding-the-intricacies-of-fleet-policies-refetch-204x64@2x.png"/>
&lt;/figure>
&lt;h2 id="policy-results-aggregation">Policy results aggregation&lt;/h2>
&lt;p>However, the main &lt;strong>Policies&lt;/strong> page is not updated. This page shows the counts of all passing and failing hosts for each policy. A worker process on one of the Fleet servers updates it once an hour. The worker calculates the counts and stores them in the &lt;strong>policy_stats&lt;/strong> table in the database. This is done for better performance of the UI. For customers with 100,000s of hosts that asynchronously report their policy results, calculating the passing and failing counts in real time was noticeably slow.&lt;/p>
&lt;figure>&lt;img src="understanding-the-intricacies-of-fleet-policies-main-policies-page-1999x978@2x.png"/>
&lt;/figure>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;p>Understanding the intricacies of Fleet policies is essential for IT professionals managing a fleet of devices. This deep dive into the mechanics of Fleet policies — from creation to execution — provides you with the necessary insights to optimize your cybersecurity strategy effectively. By leveraging these policies, you can ensure stringent security standards across your network, enhancing your organization&amp;rsquo;s digital defense. As the cyber landscape evolves, tools like Fleet remain crucial in maintaining robust and responsive security protocols. We encourage you to apply these insights in your Fleet usage, and as always, we welcome your feedback and experiences in the &lt;a class="link" href="https://fleetdm.com/support" target="_blank" rel="noopener"
>Fleet community Slack channels&lt;/a>.&lt;/p>
&lt;p>&lt;em>This article originally appeared in &lt;a class="link" href="https://fleetdm.com/guides/understanding-the-intricacies-of-fleet-policies" target="_blank" rel="noopener"
>Fleet&amp;rsquo;s blog&lt;/a>.&lt;/em>&lt;/p></description></item><item><title>Get current telemetry from your devices with live queries</title><link>https://victoronsoftware.com/posts/get-current-telemetry-from-your-devices-with-live-queries/</link><pubDate>Fri, 29 Dec 2023 00:00:00 +0000</pubDate><guid>https://victoronsoftware.com/posts/get-current-telemetry-from-your-devices-with-live-queries/</guid><description>&lt;img src="https://victoronsoftware.com/posts/get-current-telemetry-from-your-devices-with-live-queries/Live%20Query.png" alt="Featured image of post Get current telemetry from your devices with live queries" />&lt;div class="video-wrapper">
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/Jh14hNjW0Uo"
allowfullscreen
title="YouTube Video"
>
&lt;/iframe>
&lt;/div>
&lt;p>&lt;a class="link" href="https://fleetdm.com/" target="_blank" rel="noopener"
>Fleet&lt;/a> is an open-source platform for managing and gathering telemetry from devices such as laptops, desktops, VMs, etc. &lt;a class="link" href="https://www.osquery.io/" target="_blank" rel="noopener"
>Osquery&lt;/a> agents run on these devices and report to the Fleet server. One of Fleet’s features is the ability to query information from the devices in near real-time, called &lt;em>live queries&lt;/em>. This article discusses how live queries work “under the hood.”&lt;/p>
&lt;h2 id="why-a-live-query">Why a live query?&lt;/h2>
&lt;p>Live queries enable administrators to ask near real-time questions of all online devices, such as checking the encryption status of SSH keys across endpoints, or obtaining the uptime of each server within their purview. This enables them to promptly identify and address any issues, thereby reducing downtime and maintaining operational efficiency. These tasks, which would be time-consuming and complex if done manually, are streamlined through live queries, offering real-time insights into the status and posture of the entire fleet of devices helping IT and security.&lt;/p>
&lt;h2 id="live-queries-under-the-hood">Live queries under the hood&lt;/h2>
&lt;p>Live queries can be run from the web UI, the command-line interface called &lt;code>fleetctl&lt;/code>, or the REST API. The user creates a query and selects which devices will run that query. Here is an example using &lt;code>fleetctl&lt;/code> to obtain the operating system name and version for all devices:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>fleetctl query --query &lt;span style="color:#e6db74">&amp;#34;select name, version from os_version;&amp;#34;&lt;/span> --labels &lt;span style="color:#e6db74">&amp;#34;All Hosts&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>When a client initiates a live query, the server first creates a &lt;strong>Query Campaign&lt;/strong> record in the MySQL database. A Fleet deployment consists of several servers behind a load balancer, so storing the record in the DB makes all servers aware of the new query campaign.&lt;/p>
&lt;figure>&lt;img src="Live%20Query.png"/>&lt;figcaption>
&lt;h4>Query campaign&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>As devices called &lt;strong>Hosts&lt;/strong> in Fleet check in with the servers, they receive instructions to run a query. For example:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;queries&amp;#34;&lt;/span>: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;fleet_distributed_query_140&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;SELECT name, version FROM os_version;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;discovery&amp;#34;&lt;/span>: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;fleet_distributed_query_140&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;SELECT 1&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Then, the osquery agents run the actual query on their host, and write the result back to a Fleet server. As a server receives the result, it publishes it to the common cache using &lt;a class="link" href="https://redis.io/docs/interact/pubsub/" target="_blank" rel="noopener"
>Redis Pub/Sub&lt;/a>.&lt;/p>
&lt;p>Only the one server communicating with the client subscribes to the results. It processes the data from the cache, keeps track of how many hosts reported back, and communicates results back to the client. The web UI and &lt;code>fleetctl&lt;/code> interfaces use a &lt;a class="link" href="https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API" target="_blank" rel="noopener"
>WebSockets API&lt;/a>, and results are reported as they come in. The REST API, on the other hand, only sends a response after all online hosts have reported their query results.&lt;/p>
&lt;h2 id="discover-more">Discover more&lt;/h2>
&lt;p>Fleet’s live query feature represents a powerful tool in the arsenal of IT and security administrators. By harnessing the capabilities of live queries, tasks that once required extensive manual effort can now be executed swiftly and efficiently. This real-time querying ability enhances operational efficiency and significantly bolsters security and compliance measures across a range of devices.&lt;/p>
&lt;p>The integration of Fleet with Osquery agents, the flexibility offered by interfaces like the web UI, &lt;code>fleetctl&lt;/code>, and the REST API, and the efficient data handling through mechanisms like Redis Pub/Sub and WebSockets API all come together to create a robust, real-time telemetry gathering system. This system is designed to keep you informed about the current state of your device fleet, helping you make informed decisions quickly.&lt;/p>
&lt;p>As you reflect on the capabilities of live queries with Fleet, consider your network environment&amp;rsquo;s unique challenges and needs. &lt;strong>What questions could live queries help you answer about your devices?&lt;/strong> Whether it&amp;rsquo;s security audits, performance monitoring, or compliance checks, live queries offer a dynamic solution to address these concerns.&lt;/p>
&lt;p>We encourage you to explore the possibilities and share your thoughts or questions. Perhaps you’re facing a specific query challenge or an innovative use case you’ve discovered. Whatever it may be, the world of live queries is vast and ripe for exploration. Join us in &lt;a class="link" href="https://fleetdm.com/support" target="_blank" rel="noopener"
>Fleet’s Slack forums&lt;/a> to engage with a community of like-minded professionals and deepen your understanding of what live queries can achieve in your environment.&lt;/p>
&lt;p>API Documentation:&lt;/p>
&lt;ul>
&lt;li>&lt;a class="link" href="https://fleetdm.com/docs/rest-api/rest-api#run-live-query" target="_blank" rel="noopener"
>Run live query with REST API&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://github.com/fleetdm/fleet/blob/6fd06d648601edd89c01e25426e2e35ff2a8a37b/docs/Contributing/API-for-contributors.md#run-live-query" target="_blank" rel="noopener"
>Run live query with WebSockets&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;em>This article originally appeared in &lt;a class="link" href="https://fleetdm.com/guides/get-current-telemetry-from-your-devices-with-live-queries" target="_blank" rel="noopener"
>Fleet&amp;rsquo;s blog&lt;/a>.&lt;/em>&lt;/p></description></item><item><title>Nil slice versus empty slice in Go</title><link>https://victoronsoftware.com/posts/nil-slice-versus-empty-slice-in-go/</link><pubDate>Thu, 28 Dec 2023 00:00:00 +0000</pubDate><guid>https://victoronsoftware.com/posts/nil-slice-versus-empty-slice-in-go/</guid><description>&lt;img src="https://victoronsoftware.com/posts/nil-slice-versus-empty-slice-in-go/cover.png" alt="Featured image of post Nil slice versus empty slice in Go" />&lt;div class="video-wrapper">
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/q0B4q_0u4XI"
allowfullscreen
title="YouTube Video"
>
&lt;/iframe>
&lt;/div>
&lt;p>When starting to code in Go, I encountered the following situation. I needed to create an empty slice, so I did:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-go" data-lang="go">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">slice&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> []&lt;span style="color:#66d9ef">string&lt;/span>{}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>However, my IDE flagged it as a warning, and pointed me to &lt;a class="link" href="https://go.dev/wiki/CodeReviewComments#declaring-empty-slices" target="_blank" rel="noopener"
>this Go style guide passage&lt;/a>, which recommended using a nil slice instead:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-go" data-lang="go">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">slice&lt;/span> []&lt;span style="color:#66d9ef">string&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This recommendation didn&amp;rsquo;t seem right to me. How can a nil variable be better? Won’t I run into issues like null pointer exceptions and other annoyances? Well, as it turns out, that’s not how slices work in Go. When declaring a nil slice, it is not the dreaded null pointer. It is still a slice. This slice includes a slice header, but its value just happens to be nil.&lt;/p>
&lt;p>The main difference between a nil slice and an empty slice is the following. A nil slice compared to nil will return true. That’s pretty much it.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-go" data-lang="go">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#a6e22e">slice&lt;/span> &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#66d9ef">nil&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">fmt&lt;/span>.&lt;span style="color:#a6e22e">Println&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Slice is nil.&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>} &lt;span style="color:#66d9ef">else&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">fmt&lt;/span>.&lt;span style="color:#a6e22e">Println&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Slice is NOT nil.&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>When printing a nil slice, it will print like an empty slice:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-go" data-lang="go">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">fmt&lt;/span>.&lt;span style="color:#a6e22e">Printf&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Slice is: %v\n&amp;#34;&lt;/span>, &lt;span style="color:#a6e22e">slice&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre tabindex="0">&lt;code>Slice is: []
&lt;/code>&lt;/pre>&lt;p>You can append to a nil slice:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-go" data-lang="go">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">slice&lt;/span> = append(&lt;span style="color:#a6e22e">slice&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;bozo&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>You can loop over a nil slice, and the code will not enter the for loop:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-go" data-lang="go">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> &lt;span style="color:#66d9ef">range&lt;/span> &lt;span style="color:#a6e22e">slice&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">fmt&lt;/span>.&lt;span style="color:#a6e22e">Println&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;We are in a for loop.&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The length of a nil slice is 0:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-go" data-lang="go">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">fmt&lt;/span>.&lt;span style="color:#a6e22e">Printf&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;len: %#v\n&amp;#34;&lt;/span>, len(&lt;span style="color:#a6e22e">slice&lt;/span>))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre tabindex="0">&lt;code>len: 0
&lt;/code>&lt;/pre>&lt;p>And, of course, you can pass a nil slice by pointer. That’s right &amp;ndash; pass a nil slice by pointer.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-go" data-lang="go">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">func&lt;/span> &lt;span style="color:#a6e22e">passByPointer&lt;/span>(&lt;span style="color:#a6e22e">slice&lt;/span> &lt;span style="color:#f92672">*&lt;/span>[]&lt;span style="color:#66d9ef">string&lt;/span>) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">fmt&lt;/span>.&lt;span style="color:#a6e22e">Printf&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;passByPointer len: %#v\n&amp;#34;&lt;/span>, len(&lt;span style="color:#f92672">*&lt;/span>&lt;span style="color:#a6e22e">slice&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">*&lt;/span>&lt;span style="color:#a6e22e">slice&lt;/span> = append(&lt;span style="color:#f92672">*&lt;/span>&lt;span style="color:#a6e22e">slice&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;bozo&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>You will get the updated slice if the underlying slice is reassigned.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-go" data-lang="go">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">passByPointer&lt;/span>(&lt;span style="color:#f92672">&amp;amp;&lt;/span>&lt;span style="color:#a6e22e">slice&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">fmt&lt;/span>.&lt;span style="color:#a6e22e">Printf&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;len after passByPointer: %#v\n&amp;#34;&lt;/span>, len(&lt;span style="color:#a6e22e">slice&lt;/span>))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre tabindex="0">&lt;code>len after passByPointer: 1
&lt;/code>&lt;/pre>&lt;p>The code above demonstrates that a nil slice is not a nil pointer. On the other hand, you cannot dereference a nil pointer like you can a nil slice. This code causes a crash:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-go" data-lang="go">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">nullSlice&lt;/span> &lt;span style="color:#f92672">*&lt;/span>[]&lt;span style="color:#66d9ef">string&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">fmt&lt;/span>.&lt;span style="color:#a6e22e">Printf&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Crash: %#v\n&amp;#34;&lt;/span>, len(&lt;span style="color:#f92672">*&lt;/span>&lt;span style="color:#a6e22e">nullSlice&lt;/span>))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Here&amp;rsquo;s the full gist:&lt;/p>
&lt;script src="https://gist.github.com/getvictor/bff0fa45185630e264a40476207d8e4d.js">&lt;/script></description></item><item><title>Physical security meets cybersecurity with Matter</title><link>https://victoronsoftware.com/posts/physical-security-meets-cybersecurity-with-matter/</link><pubDate>Wed, 20 Dec 2023 00:00:00 +0000</pubDate><guid>https://victoronsoftware.com/posts/physical-security-meets-cybersecurity-with-matter/</guid><description>&lt;img src="https://victoronsoftware.com/posts/physical-security-meets-cybersecurity-with-matter/cover.png" alt="Featured image of post Physical security meets cybersecurity with Matter" />&lt;div class="video-wrapper">
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/mIVsLTrUork"
allowfullscreen
title="YouTube Video"
>
&lt;/iframe>
&lt;/div>
&lt;p>Matter is a recent open-source standard for connecting devices such as light switches, door locks,
motion sensors, and many others. The major goals of the standard are compatibility and
interoperability. This means that you will no longer need to be an expert hacker when trying to
control devices from multiple manufacturers under a single application. Apple, Amazon, and Google
are some of the major members driving the standard. This is great news for the majority of adopters
who haven’t yet fully embraced home automation and security.&lt;/p>
&lt;figure>&lt;img src="matter.jpeg"/>
&lt;/figure>
&lt;p>The Matter specification is published by
the &lt;a class="link" href="https://csa-iot.org/" target="_blank" rel="noopener"
>Connectivity Standards Alliance&lt;/a> (CSA) and includes a
&lt;a class="link" href="https://github.com/project-chip/connectedhomeip" target="_blank" rel="noopener"
>software development kit&lt;/a>. Version 1.0 of the
specification was released in October of 2022. In 2023,
we saw a slew of new devices and software upgrades compatible with Matter. Version 1.2 of the
specification was published in October of 2023. However, this latest specification is still missing
support for a few important device categories such as cameras and major appliances. Cameras are a
top priority for the CSA, and we may see Matter-compatible cameras in 2024.&lt;/p>
&lt;p>Matter is an important step for the management of IoT devices because it finally brings true
interoperability where it has been sorely missing for so many years. No longer will device
manufacturers need to decide and budget precious software resources to support Amazon Alexa, Google
Home, Apple HomeKit, or another connectivity hub. Customers will no longer be locked into using one
of the major home automation providers. And home automation solutions from smaller companies will
come onto the market.&lt;/p>
&lt;p>An important feature of Matter is &lt;strong>multi-admin&lt;/strong>, which means that devices can be read and
controlled by multiple clients. In Matter terminology, the device, such as a motion sensor, is
called a server or node, and the applications controlling it are called clients. For example, a
light switch may be simultaneously controlled by the manufacturer’s app, by Alexa, and by the user&amp;rsquo;s
hand-written custom API client.&lt;/p>
&lt;p>Multi-admin support means that a home or business may use one application to control their locks,
switches, and security sensors, and another application for reading telemetry from those same
devices. Businesses will find it easier to integrate physical security with cyber security. For
example, suppose a business’s device management server uses Matter to subscribe to the office door
lock. It receives an alert that &lt;em>User A&lt;/em> has entered their code. Afterwards, via regular scheduled
telemetry, it notices a successful login to &lt;em>Computer B&lt;/em>. The business SIEM (security information and
event management) system should immediately flag this suspicious sequence of events.&lt;/p>
&lt;figure>&lt;img src="cover.png"/>
&lt;/figure>
&lt;p>Of course, the example above can be accomplished today by writing some custom code or using a third party integration. What Matter brings is scalability to such security approaches. The code and integration will no longer need to be redone for each new device and version that comes onto the market.&lt;/p></description></item><item><title>SQL prepared statements are broken when scaling applications</title><link>https://victoronsoftware.com/posts/sql-prepared-statements-are-broken-when-scaling-applications/</link><pubDate>Thu, 14 Dec 2023 00:00:00 +0000</pubDate><guid>https://victoronsoftware.com/posts/sql-prepared-statements-are-broken-when-scaling-applications/</guid><description>&lt;img src="https://victoronsoftware.com/posts/sql-prepared-statements-are-broken-when-scaling-applications/cover.png" alt="Featured image of post SQL prepared statements are broken when scaling applications" />&lt;div class="video-wrapper">
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/JHoEKmNj8t8"
allowfullscreen
title="YouTube Video"
>
&lt;/iframe>
&lt;/div>
&lt;p>A prepared statement is a feature of modern databases intended to help execute the same SQL
statement multiple times. For example, the following statement is a prepared statement:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sql" data-lang="sql">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">SELECT&lt;/span> id, name &lt;span style="color:#66d9ef">FROM&lt;/span> users &lt;span style="color:#66d9ef">WHERE&lt;/span> email &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#f92672">?&lt;/span>;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The presence of an unspecified parameter, labeled “?”, makes it a prepared statement. When a
prepared statement is sent to the database, it is compiled, optimized, and stored in memory on the
database server. Subsequently, the client application may execute the same prepared statement
multiple times with different parameter values. This results in a speedup.&lt;/p>
&lt;p>Prepared statements are well suited for long and complex queries that require significant
compilation and optimization times. They are kept prepared on the DB server, and the application
must only pass the parameters to execute them.&lt;/p>
&lt;p>Another benefit of using prepared statements is the protection they provide
against &lt;a class="link" href="https://owasp.org/www-community/attacks/SQL_Injection" target="_blank" rel="noopener"
>SQL injection&lt;/a>. The application does
not need to properly escape the parameter values provided to the statement. Because of this
protection, many experts recommend always using prepared statements for accessing the database.&lt;/p>
&lt;p>However, by always using prepared statements for accessing the database, we force the SQL driver to
send the extra prepare command for every ad-hoc statement we execute. The driver sends the following
commands:&lt;/p>
&lt;ol>
&lt;li>Prepare the statement&lt;/li>
&lt;li>Execute statement with given parameters&lt;/li>
&lt;li>Close the statement (and deallocate the prepared statement created above)&lt;/li>
&lt;/ol>
&lt;p>Another issue with prepared statements is the memory requirement. In large application deployments
with large numbers of connections, prepared statements can crash your environment. This issue
happened to one of our customers.&lt;/p>
&lt;p>A prepared statement is only valid for a single session, which typically maps to a single database
connection. If the application runs multiple servers, with many connections, it may end up storing a
prepared statement for each one of those sessions.&lt;/p>
&lt;p>For example, given 100 servers with 100 connections each, we have 10,000 connections to the
database. Assuming a memory requirement of 50 KB per prepared statement (derived from the
following &lt;a class="link" href="https://blog.searce.com/how-max-prepared-stmt-count-bring-down-the-production-mysql-system-6ca28e577663" target="_blank" rel="noopener"
>article&lt;/a>),
we arrive at the maximum memory requirement of:&lt;/p>
&lt;pre tabindex="0">&lt;code>10,000 * 50 KB = 500 MB per single saved prepared statement
&lt;/code>&lt;/pre>&lt;p>Some databases also have limits on the number of prepared statements. MySQL’s
&lt;a class="link" href="https://dev.mysql.com/doc/refman/8.0/en/server-system-variables.html#sysvar_max_prepared_stmt_count" target="_blank" rel="noopener"
>max_prepared_stmt_count&lt;/a> defaults to 16,382 for the entire server. Yes, this is a global limit, and
&lt;strong>not&lt;/strong> per session. In the above example, if the application uses prepared statements for every
database access, then each database connection will always be using up 1 short-lived prepared
statement. A short-lived prepared statement is the prepared statement, as we described above, that
will be created for the purposes of executing one statement, and then immediately deallocated
afterwards. This means the above application running with a default MySQL config &lt;strong>cannot explicitly
save any prepared statements&lt;/strong> &amp;ndash; 10,000 transient prepared statements + 10,000 saved prepared
statements is greater than the max_prepared_stmt_count of 16,382.&lt;/p>
&lt;p>This is &lt;strong>extremely inconvenient&lt;/strong> for application developers, because they must keep track of:&lt;/p>
&lt;ul>
&lt;li>The number of saved prepared statements they are using&lt;/li>
&lt;li>How many application servers are running&lt;/li>
&lt;li>How many database connections each server has&lt;/li>
&lt;li>The prepared statement limits of the database&lt;/li>
&lt;/ul>
&lt;p>This detail can easily be overlooked when scaling applications.&lt;/p>
&lt;p>In the end, is it really worth using prepared statements, and especially saved prepared statements, in your application? Yes, saved prepared statements can offer performance advantages, especially for complex queries executed frequently. However they must also be kept in check.&lt;/p>
&lt;p>A few ways to mitigate prepared statement issues for large application deployments include:&lt;/p>
&lt;ul>
&lt;li>Limit the number of database connections per application server&lt;/li>
&lt;li>Increase the prepared statement limit on the database server(s)&lt;/li>
&lt;li>Limit the maximum lifespan of connections. When closing a connection, the database will deallocate all prepared statements on that connection.&lt;/li>
&lt;/ul></description></item><item><title>You need a personal dev docs DB (GitBook)</title><link>https://victoronsoftware.com/posts/you-need-a-personal-dev-docs-db-gitbook/</link><pubDate>Thu, 30 Nov 2023 00:00:00 +0000</pubDate><guid>https://victoronsoftware.com/posts/you-need-a-personal-dev-docs-db-gitbook/</guid><description>&lt;img src="https://victoronsoftware.com/posts/you-need-a-personal-dev-docs-db-gitbook/cover.png" alt="Featured image of post You need a personal dev docs DB (GitBook)" />&lt;div class="video-wrapper">
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/o-Tml_PAAeM"
allowfullscreen
title="YouTube Video"
>
&lt;/iframe>
&lt;/div>
&lt;p>At &lt;a class="link" href="https://fleetdm.com/" target="_blank" rel="noopener"
>Fleet&lt;/a>, our developer documentation is spread out throughout the codebase,
contained in a multitude of README and Markdown files. Much of the documentation is hosted
on &lt;a class="link" href="https://fleetdm.com/docs/get-started/why-fleet" target="_blank" rel="noopener"
>our webpage&lt;/a>, but not all of it.&lt;/p>
&lt;p>As developers, we need to be able to quickly search project documentation to find answers to
specific questions, such as:&lt;/p>
&lt;ul>
&lt;li>How to do a database migration&lt;/li>
&lt;li>How to run integration tests&lt;/li>
&lt;li>How to deploy a development version of to a specific OS&lt;/li>
&lt;/ul>
&lt;p>One solution is to use &lt;strong>grep&lt;/strong> or the IDE environment to search for these answers. Unfortunately,
such search methods are not optimized for text search &amp;ndash; they frequently generate no relevant
results or too many results that we must manually wade through to find the most appropriate.
Specialized documentation search tools, on the other hand, prioritize headings and whole words,
search for plural versions of the search terms, and offer other conveniences.&lt;/p>
&lt;p>The lack of good search capability for engineering docs must be solved in order to scale engineering
efforts. It is an issue because of the following side effects:&lt;/p>
&lt;ul>
&lt;li>Engineers are discouraged from writing documentation&lt;/li>
&lt;li>Documentation may be duplicated&lt;/li>
&lt;li>Senior developers are frequently interrupted when people can’t find relevant documentation&lt;/li>
&lt;/ul>
&lt;p>One solution is to use a documentation service, such as a team
wiki, &lt;a class="link" href="https://www.atlassian.com/software/confluence" target="_blank" rel="noopener"
>Confluence&lt;/a>,
or &lt;a class="link" href="https://www.gitbook.com/" target="_blank" rel="noopener"
>GitBook&lt;/a>. GitBook
integrates with git repositories, and can push documentation changes. GitBook is free for personal
use, which makes it easy to use for open source projects such
as &lt;a class="link" href="https://github.com/fleetdm/fleet" target="_blank" rel="noopener"
>fleet&lt;/a> and &lt;a class="link" href="https://github.com/osquery/osquery" target="_blank" rel="noopener"
>osquery&lt;/a>. That
said,
GitBook is a newcomer to the space, and is still reaching maturity.&lt;/p>
&lt;p>To set up a personal GitBook, make a fork of the open source projects that contain documentation
you’d like to search, and integrate them into GitBook spaces. After indexing is complete, you’ll be
able to effectively search the documentation.&lt;/p>
&lt;figure>&lt;img src="GitBook-1.png"/>
&lt;/figure>
&lt;p>To keep the forks in sync with the parent repositories, we use Github Actions. Github Actions are
free for open source projects. Searching GitHub for &lt;strong>sync-fork&lt;/strong> returned several examples. We
ended up using the following:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">Sync Fork&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">on&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">schedule&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">cron&lt;/span>: &lt;span style="color:#e6db74">&amp;#39;55 * * * *&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">workflow_dispatch&lt;/span>: &lt;span style="color:#75715e"># on button click&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">jobs&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">sync&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">runs-on&lt;/span>: &lt;span style="color:#ae81ff">ubuntu-latest&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">steps&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">Checkout repository&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">uses&lt;/span>: &lt;span style="color:#ae81ff">actions/checkout@v4&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">with&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">token&lt;/span>: &lt;span style="color:#ae81ff">${{ secrets.WORKFLOW_TOKEN }}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">fetch-depth&lt;/span>: &lt;span style="color:#ae81ff">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">Configure Git&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">run&lt;/span>: |&lt;span style="color:#e6db74">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> git config --global user.name &amp;#34;GitHub Actions Bot&amp;#34;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> git config --global user.email &amp;#34;actions@github.com&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">Merge upstream&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">run&lt;/span>: |&lt;span style="color:#e6db74">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> git remote add upstream https://github.com/fleetdm/fleet.git
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> git fetch upstream main
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> git checkout main
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> git merge upstream/main
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> git push origin main&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;strong>WORKFLOW_TOKEN&lt;/strong> above is a GitHub personal access token (PAT) that allows reading and writing
workflows in this repository. This token is not needed for repositories without workflows.&lt;/p>
&lt;p>In addition to project documentation, GitBook can be used to synchronize personal documentation
that’s being held in a private repository. There are several git-based notebook applications on the
market. In addition, Markdown notes from the popular note-taking
app &lt;a class="link" href="https://obsidian.md/" target="_blank" rel="noopener"
>Obsidian&lt;/a> can be kept in GitHub. This turns GitBook into a true
personalized developer documentation database &amp;ndash; one place to search through developer docs as well
as your own private notes.&lt;/p></description></item><item><title>Setting up a virtual router</title><link>https://victoronsoftware.com/posts/setting-up-a-virtual-router/</link><pubDate>Wed, 22 Nov 2023 00:00:00 +0000</pubDate><guid>https://victoronsoftware.com/posts/setting-up-a-virtual-router/</guid><description>&lt;img src="https://victoronsoftware.com/posts/setting-up-a-virtual-router/cover.jpeg" alt="Featured image of post Setting up a virtual router" />&lt;div class="video-wrapper">
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/uj_lB__QDTc"
allowfullscreen
title="YouTube Video"
>
&lt;/iframe>
&lt;/div>
&lt;p>Traditionally, network routers used dedicated bare metal machines. However, in the last several
years, we’ve seen a rise in software-based routers that can be deployed either on bare metal, on a
VM, or even on a container. This means these virtual routers can be used to replace existing router
software on an older router. They can run in the cloud. Or they can be installed on do-it-yourself
(DIY) hardware. A couple popular open source software-based routers
are &lt;a class="link" href="https://www.pfsense.org/" target="_blank" rel="noopener"
>pfSense&lt;/a> and &lt;a class="link" href="https://opnsense.org/" target="_blank" rel="noopener"
>OPNsense&lt;/a>.&lt;/p>
&lt;h2 id="why-use-a-virtual-router">Why use a virtual router?&lt;/h2>
&lt;p>For one, these routers offer enterprise-level features such as build-in VPN support, traffic
analysis, and extensive diagnostics, among others. Another reason is that having a virtual router
gives you the ability to experiment &amp;ndash; you can install multiple routers on top of your hypervisor,
and try all of them out. A third reason is that the virtual router may be only one of many VMs that
you run on your hardware. You can use the same piece of hardware to run a router, an ad-blocking
service, a media server, and other applications.&lt;/p>
&lt;h2 id="advanced-virtual-router-installation-and-set-up">Advanced virtual router installation and set up&lt;/h2>
&lt;p>When setting up our virtual router, we chose to
use &lt;a class="link" href="https://pve.proxmox.com/wiki/PCI%28e%29_Passthrough" target="_blank" rel="noopener"
>PCI Passthrough&lt;/a> to allow the virtual router
direct access to the NIC hardware. Direct access to hardware improves the latency of our internet
traffic. In addition, we wanted our hypervisor to sit behind the router, and not be exposed to the
public. This reduces the attack surface for potential bad agents. However, routing hypervisor
traffic through the router made our setup a bit tricker. It is like the chicken or the egg
dilemma &amp;ndash; how do you put your hypervisor behind the router when the hypervisor is responsible for
managing the router? Below is the approach we used when installing pfSense on top
of &lt;a class="link" href="https://www.proxmox.com/en/proxmox-virtual-environment/overview" target="_blank" rel="noopener"
>Proxmox Virtual
Environment (PVE)&lt;/a>.&lt;/p>
&lt;p>For the initial installation, we did not use PCI Passthrough and instead used a virtual network
bridge (&lt;strong>vmbr0&lt;/strong>). We configured the router VM to start on boot.&lt;/p>
&lt;figure>&lt;img src="Virtual-Router-1.jpg"/>&lt;figcaption>
&lt;h4>Initial virtual router configuration&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>This allowed us to continue controlling the virtual router through the PVE web GUI. We set up the
router and enabled access to it through the serial interface, which we used in the next step. Then,
we put the system into its final configuration.&lt;/p>
&lt;figure>&lt;img src="Virtual-Router-2.jpg"/>&lt;figcaption>
&lt;h4>Final virtual router configuration&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>In order to finish configuring, we had to plug in a monitor and keyboard into our hardware. We
accessed the virtual router via the serial interface from the PVE command line:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>qm terminal &lt;span style="color:#ae81ff">100&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>We updated the WAN interface to use &lt;strong>eth0&lt;/strong>. At this point, the LAN interface &lt;strong>eth1&lt;/strong> had access
to the internet.&lt;/p>
&lt;p>In addition, we added a second LAN interface for the network bridge (&lt;strong>vmbr0&lt;/strong>). We made sure
firewall configurations for both LAN interfaces were the same.&lt;/p>
&lt;p>Next, from the PVE command line, we updated the PVE IP and gateway to point at the router by
modifying the following files.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>/etc/network/interfaces
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>/etc/hosts
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>After rebooting PVE, we had access to the internet and to the PVE Web GUI from our new LAN.&lt;/p>
&lt;h2 id="updating-router-software">Updating router software&lt;/h2>
&lt;p>Using a virtual router with PCI Passthrough creates a unique challenge when doing software updates.
What if the new version doesn’t work? What if you lose all internet access.&lt;/p>
&lt;p>We can mitigate potential issues. First, we recommend always making a backup of the router VM when
upgrading. That way we can easily roll back the change. Switching to a backup, however, requires
keyboard and monitor access to your hardware, since it must be done via the PVE command line.&lt;/p>
&lt;p>Another way to safely upgrade is to spin up a second VM running updated router software. The second
VM can be either from a backup or brand new. This VM should use virtual network bridges for its
connections. Once it is properly configured, we can stop the first router VM and switch the port
connections to the second VM. This flow also requires accessing the router via the serial interface
to update the WAN/LAN interfaces.&lt;/p></description></item><item><title>Inspecting keychain files on macOS</title><link>https://victoronsoftware.com/posts/inspecting-keychain-files-on-macos/</link><pubDate>Thu, 16 Nov 2023 00:00:00 +0000</pubDate><guid>https://victoronsoftware.com/posts/inspecting-keychain-files-on-macos/</guid><description>&lt;div class="video-wrapper">
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/QBn_C2nl2ZE"
allowfullscreen
title="YouTube Video"
>
&lt;/iframe>
&lt;/div>
&lt;p>Keychains are the macOS’s method to track and protect secure information such as passwords, private keys, and certificates. Traditionally, the keychain information was stored in files, such as:&lt;/p>
&lt;pre tabindex="0">&lt;code>/Library/Keychains/System.keychain
/Library/Keychains/apsd.keychain
/System/Library/Keychains/SystemRootCertificates.keychain
/Users/&amp;lt;username&amp;gt;/Library/Keychains/login.keychain-db
&lt;/code>&lt;/pre>&lt;p>In the last several years, Apple also introduced data protection keychains, such as the iCloud
Keychain. Although the file-based keychains above are on the road to deprecation in favor of data
protection keychains, current macOS systems still heavily rely on them. It is unclear when, if
ever, these keychains will be replaced by data protection keychains.&lt;/p>
&lt;p>Inspecting file-based keychains has gotten more difficult as Apple deprecated many of the APIs
associated with them, such as &lt;a class="link" href="https://developer.apple.com/documentation/security/1396431-seckeychainopen" target="_blank" rel="noopener"
>SecKeychainOpen&lt;/a>.
In addition, excessive use of these deprecated APIs may result in corruption of the Login Keychain,
as mentioned in this &lt;a class="link" href="https://github.com/osquery/osquery/issues/7780" target="_blank" rel="noopener"
>osquery issue&lt;/a>.
By NOT using the deprecated APIs, the user only has access to the following keychains from the above list:&lt;/p>
&lt;pre tabindex="0">&lt;code>/Library/Keychains/System.keychain
/Users/&amp;lt;username&amp;gt;/Library/Keychains/login.keychain-db
&lt;/code>&lt;/pre>&lt;p>Root certificates are missing. And the APSD (Apple Push Service Daemon) keychain is missing, which is used for device management, among other things.&lt;/p>
&lt;p>So, how can app developers and IT professionals continue to have access to ALL of these keychain files?&lt;/p>
&lt;p>One way is to continue using deprecated APIs until they stop working. We recommend making a secure copy of the keychain files before accessing them with the APIs.&lt;/p>
&lt;p>Another option is to use the macOS &lt;a class="link" href="https://ss64.com/osx/security.html" target="_blank" rel="noopener"
>security&lt;/a> command line tool. For example, to list root certificates, do the following:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>sudo security find-certificate -a /System/Library/Keychains/SystemRootCertificates.keychain
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>A third, and hardest, option is to parse the &lt;a class="link" href="https://github.com/libyal/dtformats/blob/main/documentation/MacOS%20keychain%20database%20file%20format.asciidoc" target="_blank" rel="noopener"
>keychain files&lt;/a> yourself. Some details on the keychain format are available. Please leave a comment if you or someone else has created a tool to parse Apple keychains.&lt;/p>
&lt;p>The fourth option is to use an existing tool, such as &lt;a class="link" href="https://www.osquery.io/" target="_blank" rel="noopener"
>osquery&lt;/a>. Osquery is an open-source tool built for security and IT professionals. Osquery developers are working on fixing any issues to continue providing access to macOS keychain files via the following tables:&lt;/p>
&lt;ul>
&lt;li>&lt;a class="link" href="https://fleetdm.com/tables/certificates" target="_blank" rel="noopener"
>certificates&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://fleetdm.com/tables/keychain_acls" target="_blank" rel="noopener"
>keychain_acls&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://fleetdm.com/tables/keychain_items" target="_blank" rel="noopener"
>keychain_items&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Catch missed authorization checks during software development</title><link>https://victoronsoftware.com/posts/catch-missed-authorization-checks-during-software-development/</link><pubDate>Fri, 10 Nov 2023 00:00:00 +0000</pubDate><guid>https://victoronsoftware.com/posts/catch-missed-authorization-checks-during-software-development/</guid><description>&lt;div class="video-wrapper">
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/jbkPLQpzPtc"
allowfullscreen
title="YouTube Video"
>
&lt;/iframe>
&lt;/div>
&lt;p>Authorization is giving permission to a user to do an action on the server.
As developers, we must ensure that users are only allowed to do what they are authorized.&lt;/p>
&lt;p>One way to ensure that authorization has happened is to loudly flag when it hasn&amp;rsquo;t.
This is how we do it at &lt;a class="link" href="https://www.fleetdm.com" target="_blank" rel="noopener"
>Fleet Device Management&lt;/a>.&lt;/p>
&lt;p>In our code base, we use the &lt;a class="link" href="https://github.com/go-kit/kit" target="_blank" rel="noopener"
>go-kit library&lt;/a>. Most of the general endpoints are created
in the &lt;a class="link" href="https://github.com/fleetdm/fleet/blob/36421bd5055d37a4c39a04e0f9bd96ad47951131/server/service/handler.go#L729" target="_blank" rel="noopener"
>handler.go&lt;/a> file. For example:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-go" data-lang="go">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// user-authenticated endpoints
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">ue&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">newUserAuthenticatedEndpointer&lt;/span>(&lt;span style="color:#a6e22e">svc&lt;/span>, &lt;span style="color:#a6e22e">opts&lt;/span>, &lt;span style="color:#a6e22e">r&lt;/span>, &lt;span style="color:#a6e22e">apiVersions&lt;/span>&lt;span style="color:#f92672">...&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">ue&lt;/span>.&lt;span style="color:#a6e22e">POST&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;/api/_version_/fleet/trigger&amp;#34;&lt;/span>, &lt;span style="color:#a6e22e">triggerEndpoint&lt;/span>, &lt;span style="color:#a6e22e">triggerRequest&lt;/span>{})
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Every endpoint calls &lt;strong>kithttp.NewServer&lt;/strong> and wraps the endpoint with our &lt;strong>AuthzCheck&lt;/strong>.
From &lt;a class="link" href="https://github.com/fleetdm/fleet/blob/36421bd5055d37a4c39a04e0f9bd96ad47951131/server/service/handler.go#L729" target="_blank" rel="noopener"
>handler.go&lt;/a>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-go" data-lang="go">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">e&lt;/span> = &lt;span style="color:#a6e22e">authzcheck&lt;/span>.&lt;span style="color:#a6e22e">NewMiddleware&lt;/span>().&lt;span style="color:#a6e22e">AuthzCheck&lt;/span>()(&lt;span style="color:#a6e22e">e&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">kithttp&lt;/span>.&lt;span style="color:#a6e22e">NewServer&lt;/span>(&lt;span style="color:#a6e22e">e&lt;/span>, &lt;span style="color:#a6e22e">decodeFn&lt;/span>, &lt;span style="color:#a6e22e">encodeResponse&lt;/span>, &lt;span style="color:#a6e22e">opts&lt;/span>&lt;span style="color:#f92672">...&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;figure>&lt;img src="AuthzCheck.jpg"/>
&lt;/figure>
&lt;p>This means that after the business logic is processed, the AuthzCheck is called.
This check ensures that authorization was checked. Otherwise, an error is returned.
From &lt;a class="link" href="https://github.com/fleetdm/fleet/blob/36421bd5055d37a4c39a04e0f9bd96ad47951131/server/service/middleware/authzcheck/authzcheck.go#L51" target="_blank" rel="noopener"
>authzcheck.go&lt;/a>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-go" data-lang="go">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// If authorization was not checked, return a response that will
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// marshal to a generic error and log that the check was missed.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">if&lt;/span> !&lt;span style="color:#a6e22e">authzctx&lt;/span>.&lt;span style="color:#a6e22e">Checked&lt;/span>() {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// Getting to here means there is an authorization-related bug in our code.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">nil&lt;/span>, &lt;span style="color:#a6e22e">authz&lt;/span>.&lt;span style="color:#a6e22e">CheckMissingWithResponse&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This additional check is useful during our development and QA process, to ensure that authorization always happens in our business logic.&lt;/p>
&lt;p>&lt;em>This article originally appeared in &lt;a class="link" href="https://fleetdm.com/guides/catch-missed-authorization-checks-during-software-development" target="_blank" rel="noopener"
>Fleet&amp;rsquo;s blog&lt;/a>.&lt;/em>&lt;/p></description></item><item><title>Search</title><link>https://victoronsoftware.com/page/search/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://victoronsoftware.com/page/search/</guid><description/></item></channel></rss>